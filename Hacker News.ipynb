{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "In this project, we'll examine a dataset of submissions to the popular technology site, *[Hacker News](https://news.ycombinator.com/). Hacker News is a social news website focusing on computer science and entrepreneurship. It is run by the investment fund and startup incubator Y Combinator. In general, content that can be submitted is defined as \"anything that gratifies one's intellectual curiosity.\"* [<sup>1</sup>](#fn1)\n",
    "\n",
    "In this analysis, we're specifically interested in posts with titles that begin with either `Ask HN` or `Show HN`. Users submit `Ask HN` posts to ask the Hacker News community a specific question. Similarly, users submit `Show HN` posts to show the community a project, product, or something interesting.\n",
    "\n",
    "We'll compare these two types of posts to determine the following:\n",
    "1. Do `Ask HN` or `Show HN` posts receive more comments on average?\n",
    "2. Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "1 <span id=\"fn1\">[Wikipedia: Hacker News](https://en.wikipedia.org/wiki/Hacker_News)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "The full datset of Hacker News posts for the twelve-month period ending on September 26, 2016 can be found [here](https://www.kaggle.com/datasets/hacker-news/hacker-news-posts). For this analysis, we have reduced the dataset from almost 300,000 rows to about 20,000 rows by removing all submissions that didn't recieve any comments and then randomly sampling from the remaining submissions.\n",
    "\n",
    "### Open File\n",
    "\n",
    "First, we open the file and look at the first five rows of the dataset. The first row in the dataset contains descriptions for the columns. They are:\n",
    "\n",
    "* `id`: the unique identifier from Hacker News for the post\n",
    "* `title`: the title of the post\n",
    "* `url`: the URL linked in the post, if the post contains a URL\n",
    "* `num_points`: the total number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "* `num_comments`: the number of comments on the post\n",
    "* `author`: the username of the person who submitted the post\n",
    "* `created_at`: the date and time of the post's submission to Hacker News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "\n",
    "for row in hn[:5]:\n",
    "    print(row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Header\n",
    "\n",
    "In order to better work with the data, we remove the first row containing the column descriptions and separate it out as `header`. Then we look at `header` and the new five first rows of the dataset to verify that the column-descriptions header was removed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(headers)\n",
    "for row in hn[:5]:\n",
    "    print('\\n')\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Data\n",
    "\n",
    "### Separate `Ask HN` and `Show HN` Posts\n",
    "\n",
    "Our first goal is to see whether `Ask HN` or `Show HN` posts have more comments on average. To do this, we'll separate out `Ask HN` and `Show HN` posts from all of the posts and see how many of each we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of Ask HN posts: 1744\n",
      "Number of Show HN posts: 1162\n",
      "Number of other posts: 17194\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "print('\\n')\n",
    "print(\"Number of Ask HN posts: \" + str(len(ask_posts)))\n",
    "print(\"Number of Show HN posts: \" + str(len(show_posts)))\n",
    "print(\"Number of other posts: \" + str(len(other_posts)))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Average Number of Comments Per Type of Post\n",
    "\n",
    "Now that we know how many `Ask HN` and `Show HN` posts we are working with and have separated them into their own list, we need to find how many comments each type of post receives on average. To do this, we'll simply add up all of the comments in each list and divide by the total number of posts in the respective lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mAverage number of comments per type of Hacker News post\u001b[0m\n",
      "Average number of comments on Ask HN posts: 14.04\n",
      "Average number of comments on Show HN posts: 10.32\n",
      "Average number of comments on all other posts: 26.87\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "total_other_comments = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    total_ask_comments += int(post[4])\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "\n",
    "for post in show_posts:\n",
    "    total_show_comments += int(post[4])\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "for post in other_posts:\n",
    "    total_other_comments += int(post[4])\n",
    "avg_other_comments = total_other_comments / len(other_posts)\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1m' + \"Average number of comments per type of Hacker News post\" + '\\033[0m')\n",
    "print(\"Average number of comments on Ask HN posts: \" + str(round(avg_ask_comments, 2)))\n",
    "print(\"Average number of comments on Show HN posts: \" + str(round(avg_show_comments, 2)))\n",
    "print(\"Average number of comments on all other posts: \" + str(round(avg_other_comments, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do `Ask HN` or `Show HN` Posts Receive More Comments on Average?\n",
    "\n",
    "As we can see, `Ask HN` posts receive, on average, about 35% more comments than do `Show HN` posts. Posts which do not fall into either category receive about 91% more comments than `Ask HN` posts and 160% more comments than `Show HN` posts. However, since we're only interested in `Ask HN` and `Show HN` posts and since ask posts generally receive more comments than show posts, we'll focus our remaining analysis just on these posts.\n",
    "\n",
    "### Analyzing `Ask HN` Comments and Posts by Hour of Post Creation\n",
    "\n",
    "Our next step will be to determine whether `Ask HN` posts created at a certain time are more likely to attract comments. To do this, we'll look at how many ask posts were created in each hour of the day along with the total number of comments these posts received. Note that times are listed in Eastern Standard Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    result_list.append([post[6], int(post[4])])\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for result in result_list:\n",
    "    time_created = dt.datetime.strptime(result[0], \"%m/%d/%Y %H:%M\")\n",
    "    hour_created = time_created.strftime(\"%H\")\n",
    "    if hour_created not in counts_by_hour:\n",
    "        counts_by_hour[hour_created] = 1\n",
    "        comments_by_hour[hour_created] = result[1]\n",
    "    else:\n",
    "        counts_by_hour[hour_created] += 1\n",
    "        comments_by_hour[hour_created] += result[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Number of Comments for `Ask HN` Posts by Hour\n",
    "\n",
    "Now that we have frequency tables for how many posts were created in each hour of the day as well as how many comments these hour-separated posts received, some simple arithmetic can calculate the average number of comments each post received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['09', 5.5777777777777775]\n",
      "['13', 14.741176470588234]\n",
      "['10', 13.440677966101696]\n",
      "['14', 13.233644859813085]\n",
      "['16', 16.796296296296298]\n",
      "['23', 7.985294117647059]\n",
      "['12', 9.41095890410959]\n",
      "['17', 11.46]\n",
      "['15', 38.5948275862069]\n",
      "['21', 16.009174311926607]\n",
      "['20', 21.525]\n",
      "['02', 23.810344827586206]\n",
      "['18', 13.20183486238532]\n",
      "['03', 7.796296296296297]\n",
      "['05', 10.08695652173913]\n",
      "['19', 10.8]\n",
      "['01', 11.383333333333333]\n",
      "['22', 6.746478873239437]\n",
      "['08', 10.25]\n",
      "['04', 7.170212765957447]\n",
      "['00', 8.127272727272727]\n",
      "['06', 9.022727272727273]\n",
      "['07', 7.852941176470588]\n",
      "['11', 11.051724137931034]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for c in comments_by_hour:\n",
    "    avg_by_hour.append([c, (comments_by_hour[c] / counts_by_hour[c])])\n",
    "    \n",
    "for item in avg_by_hour:\n",
    "    print(item)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting and Printing the Data for Ease of Use\n",
    "\n",
    "As we can see, the information above isn't particularly easy to understand, so let's take a bit of time to better organize the data before attempting an analysis. We'll begin by swapping the hour and the average number of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.5777777777777775, '09']\n",
      "[14.741176470588234, '13']\n",
      "[13.440677966101696, '10']\n",
      "[13.233644859813085, '14']\n",
      "[16.796296296296298, '16']\n",
      "[7.985294117647059, '23']\n",
      "[9.41095890410959, '12']\n",
      "[11.46, '17']\n",
      "[38.5948275862069, '15']\n",
      "[16.009174311926607, '21']\n",
      "[21.525, '20']\n",
      "[23.810344827586206, '02']\n",
      "[13.20183486238532, '18']\n",
      "[7.796296296296297, '03']\n",
      "[10.08695652173913, '05']\n",
      "[10.8, '19']\n",
      "[11.383333333333333, '01']\n",
      "[6.746478873239437, '22']\n",
      "[10.25, '08']\n",
      "[7.170212765957447, '04']\n",
      "[8.127272727272727, '00']\n",
      "[9.022727272727273, '06']\n",
      "[7.852941176470588, '07']\n",
      "[11.051724137931034, '11']\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for hour, comments in avg_by_hour:\n",
    "    swap_avg_by_hour.append([comments, hour])\n",
    "    \n",
    "for item in swap_avg_by_hour:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only slightly, if at all, better, so let's sort the swap so that we can more easily determine the hours which received the most comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.5948275862069, '15']\n",
      "[23.810344827586206, '02']\n",
      "[21.525, '20']\n",
      "[16.796296296296298, '16']\n",
      "[16.009174311926607, '21']\n",
      "[14.741176470588234, '13']\n",
      "[13.440677966101696, '10']\n",
      "[13.233644859813085, '14']\n",
      "[13.20183486238532, '18']\n",
      "[11.46, '17']\n",
      "[11.383333333333333, '01']\n",
      "[11.051724137931034, '11']\n",
      "[10.8, '19']\n",
      "[10.25, '08']\n",
      "[10.08695652173913, '05']\n",
      "[9.41095890410959, '12']\n",
      "[9.022727272727273, '06']\n",
      "[8.127272727272727, '00']\n",
      "[7.985294117647059, '23']\n",
      "[7.852941176470588, '07']\n",
      "[7.796296296296297, '03']\n",
      "[7.170212765957447, '04']\n",
      "[6.746478873239437, '22']\n",
      "[5.5777777777777775, '09']\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "for item in sorted_swap:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data in good order, let's format the data for easier reading and separate out the five highest values to help us draw some conclusions.\n",
    "\n",
    "## Do Posts Created at a Certain Time Receive More Comments on Average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mTop 5 Hours for Ask Posts Comments\u001b[0m\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print('\\n')\n",
    "print('\\033[1m' + \"Top 5 Hours for Ask Posts Comments\" + '\\033[0m')\n",
    "for comments, hour in sorted_swap[:5]:\n",
    "    print(\"{}: {:.2f} average comments per post\".format(\n",
    "        dt.datetime.strptime(hour, '%H').strftime('%H:%M'), comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Looking at the data, `Ask HN` posts receive more comments than `Show HN` posts. This is possibly because asking a question is more likely to elicit a response than simply showing something. A post that is showing or demonstrating something could fulfill its purpose by getting lots of views and generate a lot of interest without any comments. A post that is asking a question, however, by definition needs at least one answer to complete its stated purpose.\n",
    "\n",
    "As to the question of whether posting at a certain time receives more comments, the data suggests that it is best to post in the afternoon and evening as the top five hours to receive the most comments all occurred between 3:00PM Eastern (12:00 PM Pacific, 8:00 PM BST) and 02:00AM Eastern (11:00PM Pacific, 07:00 AM BST)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
